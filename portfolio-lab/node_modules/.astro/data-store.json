[["Map",1,2,9,10,27,28],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.0","content-config-digest","c80172362d07114b","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://aniket.ink\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","research",["Map",11,12],"autonomous-navigation",{"id":11,"data":13,"body":22,"filePath":23,"digest":24,"legacyId":25,"deferredRender":26},{"title":14,"description":15,"date":16,"pdf":17,"tags":18},"Autonomous Navigation in Unstructured Environments","A study on SLAM algorithms for off-road robotics.","2023-05-15","https://arxiv.org/pdf/1706.09597.pdf",[19,20,21],"ROBOTICS","SLAM","RESEARCH","## Abstract\n\nThis paper explores the challenges of autonomous navigation in unstructured environments, focusing on the application of Simultaneous Localization and Mapping (SLAM) algorithms. We propose a novel approach that integrates visual and lidar data to improve robustness.\n\n## Methodology\n\nWe utilized a custom-built 4-wheeled rover equipped with a Velodyne VLP-16 Lidar and a ZED 2 Stereo Camera. The sensor fusion was performed using an Extended Kalman Filter (EKF).\n\n## Results\n\nOur experiments demonstrate a 15% improvement in localization accuracy compared to standard lidar-only methods.","src/content/research/autonomous-navigation.mdx","10172476748274f0","autonomous-navigation.mdx",true,"projects",["Map",29,30,43,44,54,55,68,69,79,80],"inverse-kinematics",{"id":29,"data":31,"body":39,"filePath":40,"digest":41,"legacyId":42,"deferredRender":26},{"title":32,"description":33,"date":34,"tags":35,"status":38},"Real Handwritten Test","Testing the dark mode inversion engine.","2023-11-22",[36,37],"TEST","HANDWRITING","Building","import Handwritten from '../../components/Handwritten.astro';\nimport LabNote from '../../components/LabNote.astro';\n\n## The Derivation\n\n\u003CLabNote>\n  \u003Cdiv slot=\"text\">\n    \u003Cp>\n      We start by defining the geometric constraints of the robot arm. \n      Because the servo rotates on the Z-axis, we can simplify the \n      problem into a 2D planar calculation first.\n    \u003C/p>\n    \u003Cp>\n      As you can see in the diagram, the angle \u003Cstrong>Theta-2\u003C/strong> \n      is derived using the Law of Cosines on the triangle formed by \n      Link 1 and Link 2.\n    \u003C/p>\n    \u003Cp>\n      This approach saves computational power compared to using \n      transformation matrices for every single joint.\n    \u003C/p>\n  \u003C/div>\n\n  \u003Cdiv slot=\"visual\">\n    \u003CHandwritten \n      src=\"/math-dark.png\" \n      invert={false} \n      caption=\"Fig 1. My hand calculations for the Elbow Joint\" \n    />\n  \u003C/div>\n\u003C/LabNote>\n\n\n## Implementation details\n\nAfter deriving the formula, I realized that \u003CHandwritten src=\"/notes.png\" inline={true} invert={true} /> was actually zero in this specific configuration. This simplified the Python code significantly.","src/content/projects/inverse-kinematics.mdx","baf1a70ba2db213d","inverse-kinematics.mdx","jhbcjhb",{"id":43,"data":45,"body":50,"filePath":51,"digest":52,"legacyId":53,"deferredRender":26},{"title":43,"description":46,"date":47,"tags":48,"status":38},"djhbdjhb","2025-11-22",[49],"bdbdkj","import Handwritten from '../../components/Handwritten.astro';\nimport LabNote from '../../components/LabNote.astro';\n\n## Overview\n\nStart typing your project details here...\n\n\n\n## Implementation","src/content/projects/jhbcjhb.mdx","9b190929f5f8e3ae","jhbcjhb.mdx","robot-arm",{"id":54,"data":56,"body":64,"filePath":65,"digest":66,"legacyId":67,"deferredRender":26},{"title":57,"description":58,"date":34,"tags":59,"status":63},"6-DOF Robot Arm Kinematics","Solving inverse kinematics using Python and iPad sketches.",[60,61,62],"robotics","math","python","prototyping","import Handwritten from '../../components/Handwritten.astro';\n\n## The Challenge\n\nI needed to calculate the joint angles for the end-effector to reach coordinate $(x, y, z)$. The standard geometric approach was getting messy.\n\n### Initial Thoughts\n\nI started by sketching the link lengths on my iPad.\n\n\u003CHandwritten \n  src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Analytic_geometry_parabola.svg/1200px-Analytic_geometry_parabola.svg.png\" \n  alt=\"Sketch of robot arm geometry\" \n  caption=\"Figure 1: Rough calculation of the elbow joint angle (theta 2)\" \n/>\n\n*Note: The image above is just a placeholder from the internet, but notice how the 'Handwritten' component automatically inverted the colors to make it look like white chalk on a blackboard.*\n\n## The Code\n\nOnce the math was settled, I implemented it in Python:\n\n```python\nimport numpy as np\n\ndef inverse_kinematics(x, y, z):\n    # Calculate base angle\n    theta1 = np.arctan2(y, x)\n    return theta1","src/content/projects/robot-arm.mdx","d1bed3f61ef54ddc","robot-arm.mdx","test-note",{"id":68,"data":70,"body":75,"filePath":76,"digest":77,"legacyId":78,"deferredRender":26},{"title":71,"description":72,"date":34,"tags":73,"status":74},"Handwriting Engine Test","Verifying the CSS color inversion.",[36],"Live","import Handwritten from '../../components/Handwritten.astro';\n\nHere is a test of the raw CSS inversion engine.\n\n\u003CHandwritten \n  src=\"/math-dark.png\" \n  alt=\"Test Note\" \n  caption=\"Figure 1: If you see white text on dark background, it works.\" \n/>","src/content/projects/test-note.mdx","d8e8f774ea6d1681","test-note.mdx","jhbjhb",{"id":79,"data":81,"body":85,"filePath":86,"digest":87,"legacyId":88,"deferredRender":26},{"title":79,"description":82,"date":47,"tags":83,"status":38},"jhbkkj",[84],"kjnkjn","import Handwritten from '../../components/Handwritten.astro';\nimport LabNote from '../../components/LabNote.astro';\n\n## The Problem\n\nDescribe the engineering challenge here...\n\n\u003CLabNote>\n  \u003Cdiv slot=\"text\">\n    \u003Cp>\n      Explain your thought process here. \n      This text will appear on the left side of the screen.\n    \u003C/p>\n  \u003C/div>\n  \u003Cdiv slot=\"visual\">\n    {/* Your image will auto-insert here */}\n    \u003CHandwritten src=\"/uploads/jhbjhb.jpg\" caption=\"Figure 1: Initial Sketch\" />\n  \u003C/div>\n\u003C/LabNote>\n\n## The Solution\n\nExplain how you solved it...","src/content/projects/jhbjhb.mdx","bf25cd848d987cf8","jhbjhb.mdx"]